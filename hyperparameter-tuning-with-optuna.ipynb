{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport subprocess\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom IPython.display import Video, display\n\nfrom scipy.optimize import minimize\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import (roc_auc_score, matthews_corrcoef)\n\nimport xgboost as xgb\nimport lightgbm\n\nimport torch\nimport optuna\nfrom optuna import Trial, visualization\nfrom optuna.samplers import TPESampler\n\nif torch.cuda.is_available():\n    import cupy \n    import cudf\n    from cuml import ForestInference","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def setup(cfg):\n    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # set dirs\n    cfg.INPUT = f'../input/{cfg.COMPETITION}'\n    cfg.EXP = cfg.NAME\n    cfg.OUTPUT_EXP = cfg.NAME\n    cfg.SUBMISSION = './'\n    cfg.DATASET = '../input/'\n\n    cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n    cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n    cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n\n    # make dirs\n    for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n        os.makedirs(d, exist_ok=True)\n        \n    return cfg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==============================\n# function\n# ==============================\n# ref: https://www.kaggle.com/code/robikscube/nfl-player-contact-detection-getting-started\ndef add_contact_id(df):\n    # Create contact ids\n    df[\"contact_id\"] = (\n        df[\"game_play\"]\n        + \"_\"\n        + df[\"step\"].astype(\"str\")\n        + \"_\"\n        + df[\"nfl_player_id_1\"].astype(\"str\")\n        + \"_\"\n        + df[\"nfl_player_id_2\"].astype(\"str\")\n    )\n    return df\n\ndef expand_contact_id(df):\n    \"\"\"\n    Splits out contact_id into seperate columns.\n    \"\"\"\n    df[\"game_play\"] = df[\"contact_id\"].str[:12]\n    df[\"step\"] = df[\"contact_id\"].str.split(\"_\").str[-3].astype(\"int\")\n    df[\"nfl_player_id_1\"] = df[\"contact_id\"].str.split(\"_\").str[-2]\n    df[\"nfl_player_id_2\"] = df[\"contact_id\"].str.split(\"_\").str[-1]\n    return df\n\n# cross validation\ndef get_groupkfold(train, target_col, group_col, n_splits):\n    kf = GroupKFold(n_splits=n_splits)\n    generator = kf.split(train, train[target_col], train[group_col])\n    fold_series = []\n    for fold, (idx_train, idx_valid) in enumerate(generator):\n        fold_series.append(pd.Series(fold, index=idx_valid))\n    fold_series = pd.concat(fold_series).sort_index()\n    return fold_series\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==============================\n# read data\n# ==============================\ncfg = setup(Config)\n\nif not torch.cuda.is_available():\n    tr_tracking = pd.read_csv(os.path.join(cfg.INPUT, 'train_player_tracking.csv'), parse_dates=[\"datetime\"])\n    te_tracking = pd.read_csv(os.path.join(cfg.INPUT, 'test_player_tracking.csv'), parse_dates=[\"datetime\"])\n    # tr_helmets = pd.read_csv(os.path.join(cfg.INPUT, 'train_baseline_helmets.csv'))\n    # te_helmets = pd.read_csv(os.path.join(cfg.INPUT, 'test_baseline_helmets.csv'))\n    # tr_video_metadata = pd.read_csv(os.path.join(cfg.INPUT, 'train_video_metadata.csv'))\n    # te_video_metadata = pd.read_csv(os.path.join(cfg.INPUT, 'test_video_metadata.csv'))\n    sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n\n    train = pd.read_csv(os.path.join(cfg.INPUT, 'train_labels.csv'), parse_dates=[\"datetime\"])\n    test = expand_contact_id(sub)\n    \nelse:\n    tr_tracking = cudf.read_csv(os.path.join(cfg.INPUT, 'train_player_tracking.csv'), parse_dates=[\"datetime\"])\n    te_tracking = cudf.read_csv(os.path.join(cfg.INPUT, 'test_player_tracking.csv'), parse_dates=[\"datetime\"])\n    # tr_helmets = cudf.read_csv(os.path.join(cfg.INPUT, 'train_baseline_helmets.csv'))\n    # te_helmets = cudf.read_csv(os.path.join(cfg.INPUT, 'test_baseline_helmets.csv'))\n    # tr_video_metadata = cudf.read_csv(os.path.join(cfg.INPUT, 'train_video_metadata.csv'))\n    # te_video_metadata = cudf.read_csv(os.path.join(cfg.INPUT, 'test_video_metadata.csv'))\n    sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n\n    train = cudf.read_csv(os.path.join(cfg.INPUT, 'train_labels.csv'), parse_dates=[\"datetime\"])\n    test = cudf.DataFrame(expand_contact_id(sub))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==============================\n# feature engineering\n# ==============================\ndef create_features(df, tr_tracking, merge_col=\"step\", use_cols=[\"x_position\", \"y_position\"]):\n    output_cols = []\n    df_combo = (\n        df.astype({\"nfl_player_id_1\": \"str\"})\n        .merge(\n            tr_tracking.astype({\"nfl_player_id\": \"str\"})[\n                [\"game_play\", merge_col, \"nfl_player_id\",] + use_cols\n            ],\n            left_on=[\"game_play\", merge_col, \"nfl_player_id_1\"],\n            right_on=[\"game_play\", merge_col, \"nfl_player_id\"],\n            how=\"left\",\n        )\n        .rename(columns={c: c+\"_1\" for c in use_cols})\n        .drop(\"nfl_player_id\", axis=1)\n        .merge(\n            tr_tracking.astype({\"nfl_player_id\": \"str\"})[\n                [\"game_play\", merge_col, \"nfl_player_id\"] + use_cols\n            ],\n            left_on=[\"game_play\", merge_col, \"nfl_player_id_2\"],\n            right_on=[\"game_play\", merge_col, \"nfl_player_id\"],\n            how=\"left\",\n        )\n        .drop(\"nfl_player_id\", axis=1)\n        .rename(columns={c: c+\"_2\" for c in use_cols})\n        .sort_values([\"game_play\", merge_col, \"nfl_player_id_1\", \"nfl_player_id_2\"])\n        .reset_index(drop=True)\n    )\n    output_cols += [c+\"_1\" for c in use_cols]\n    output_cols += [c+\"_2\" for c in use_cols]\n    \n    if (\"x_position\" in use_cols) & (\"y_position\" in use_cols):\n        index = df_combo['x_position_2'].notnull()\n        if torch.cuda.is_available():\n            index = index.to_array()\n        distance_arr = np.full(len(index), np.nan)\n        tmp_distance_arr = np.sqrt(\n            np.square(df_combo.loc[index, \"x_position_1\"] - df_combo.loc[index, \"x_position_2\"])\n            + np.square(df_combo.loc[index, \"y_position_1\"]- df_combo.loc[index, \"y_position_2\"])\n        )\n        if torch.cuda.is_available():\n            tmp_distance_arr = tmp_distance_arr.to_array()\n        distance_arr[index] = tmp_distance_arr\n        df_combo['distance'] = distance_arr\n        output_cols += [\"distance\"]\n        \n    df_combo['G_flug'] = (df_combo['nfl_player_id_2']==\"G\")\n    output_cols += [\"G_flug\"]\n    return df_combo, output_cols\n\n\nuse_cols = [\n    'x_position', 'y_position', 'speed', 'distance',\n    'direction', 'orientation', 'acceleration', 'sa'\n]\ntrain, feature_cols = create_features(train, tr_tracking, use_cols=use_cols)\ntest, feature_cols = create_features(test, te_tracking, use_cols=use_cols)\nif torch.cuda.is_available():\n    train = train.to_pandas()\n    test = test.to_pandas()\n\ndisplay(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DISTANCE_THRESH = 2\n\ntrain_y = train['contact'].values\noof_pred = np.zeros(len(train))\ncond_dis_train = (train['distance']<=DISTANCE_THRESH) | (train['distance'].isna())\ncond_dis_test = (test['distance']<=DISTANCE_THRESH) | (test['distance'].isna())\n\ntrain = train[cond_dis_train]\ntrain.reset_index(inplace = True, drop = True)\n\nprint('number of train data : ',len(train))\n\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLUSTERS = [10, 50, 100, 500]\n\ndef add_step_pct(df, cluster):\n    df['step_pct'] = cluster * (df['step']-min(df['step']))/(max(df['step'])-min(df['step']))\n    df['step_pct'] = df['step_pct'].apply(np.ceil).astype(np.int32)\n    return df\n\nfor cluster in CLUSTERS:\n    train = train.groupby('game_play').apply(lambda x:add_step_pct(x,cluster))\n    test = test.groupby('game_play').apply(lambda x:add_step_pct(x,cluster))\n\n    for helmet_view in ['Sideline', 'Endzone']:\n        helmet_train = pd.read_csv('/kaggle/input/nfl-player-contact-detection/train_baseline_helmets.csv')\n        helmet_train.loc[helmet_train['view']=='Endzone2','view'] = 'Endzone'\n        helmet_test = pd.read_csv('/kaggle/input/nfl-player-contact-detection/test_baseline_helmets.csv')\n        helmet_test.loc[helmet_test['view']=='Endzone2','view'] = 'Endzone'\n\n        helmet_train.rename(columns = {'frame': 'step'}, inplace = True)\n        helmet_train = helmet_train.groupby('game_play').apply(lambda x:add_step_pct(x,cluster))\n        helmet_test.rename(columns = {'frame': 'step'}, inplace = True)\n        helmet_test = helmet_test.groupby('game_play').apply(lambda x:add_step_pct(x,cluster))\n        helmet_train = helmet_train[helmet_train['view']==helmet_view]\n        helmet_test = helmet_test[helmet_test['view']==helmet_view]\n\n        helmet_train['helmet_id'] = helmet_train['game_play'] + '_' + helmet_train['nfl_player_id'].astype(str) + '_' + helmet_train['step_pct'].astype(str)\n        helmet_test['helmet_id'] = helmet_test['game_play'] + '_' + helmet_test['nfl_player_id'].astype(str) + '_' + helmet_test['step_pct'].astype(str)\n\n        helmet_train = helmet_train[['helmet_id', 'left', 'width', 'top', 'height']].groupby('helmet_id').mean().reset_index()\n        helmet_test = helmet_test[['helmet_id', 'left', 'width', 'top', 'height']].groupby('helmet_id').mean().reset_index()\n        for player_ind in [1, 2]:\n            train['helmet_id'] = train['game_play'] + '_' + train['nfl_player_id_'+str(player_ind)].astype(str) + \\\n                                    '_' + train['step_pct'].astype(str)\n            test['helmet_id'] = test['game_play'] + '_' + test['nfl_player_id_'+str(player_ind)].astype(str) + \\\n                                    '_' + test['step_pct'].astype(str)\n\n            train = train.merge(helmet_train, how = 'left')\n            test = test.merge(helmet_test, how = 'left')\n\n            train.rename(columns = {i:i+'_'+helmet_view+'_'+str(cluster)+'_'+str(player_ind) for i in ['left', 'width', 'top', 'height']}, inplace = True)\n            test.rename(columns = {i:i+'_'+helmet_view+'_'+str(cluster)+'_'+str(player_ind) for i in ['left', 'width', 'top', 'height']}, inplace = True)\n\n            del train['helmet_id'], test['helmet_id']\n            gc.collect()\n\n            feature_cols += [i+'_'+helmet_view+'_'+str(cluster)+'_'+str(player_ind) for i in ['left', 'width', 'top', 'height']]\n        del helmet_train, helmet_test\n        gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for cluster in CLUSTERS:\n    for helmet_view in ['Sideline', 'Endzone']:\n        train.loc[train['G_flug']==True,'left_'+helmet_view+'_'+str(cluster)+'_2'] = train.loc[train['G_flug']==True,'left_'+helmet_view+'_'+str(cluster)+'_1']\n        train.loc[train['G_flug']==True,'top_'+helmet_view+'_'+str(cluster)+'_2'] = train.loc[train['G_flug']==True,'top_'+helmet_view+'_'+str(cluster)+'_1']\n        train.loc[train['G_flug']==True,'width_'+helmet_view+'_'+str(cluster)+'_2'] = 0\n        train.loc[train['G_flug']==True,'height_'+helmet_view+'_'+str(cluster)+'_2'] = 0\n        \n        test.loc[test['G_flug']==True,'left_'+helmet_view+'_'+str(cluster)+'_2'] = test.loc[test['G_flug']==True,'left_'+helmet_view+'_'+str(cluster)+'_1']\n        test.loc[test['G_flug']==True,'top_'+helmet_view+'_'+str(cluster)+'_2'] = test.loc[test['G_flug']==True,'top_'+helmet_view+'_'+str(cluster)+'_1']\n        test.loc[test['G_flug']==True,'width_'+helmet_view+'_'+str(cluster)+'_2'] = 0\n        test.loc[test['G_flug']==True,'height_'+helmet_view+'_'+str(cluster)+'_2'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [i[:-2] for i in train.columns if i[-2:]=='_1' and i!='nfl_player_id_1']\ntrain[[i+'_diff' for i in cols]] = np.abs(train[[i+'_1' for i in cols]].values - train[[i+'_2' for i in cols]].values)\ntest[[i+'_diff' for i in cols]] = np.abs(test[[i+'_1' for i in cols]].values - test[[i+'_2' for i in cols]].values)\nfeature_cols += [i+'_diff' for i in cols]\n\ncols = ['x_position', 'y_position', 'speed', 'distance', 'direction', 'orientation', 'acceleration', 'sa']\ntrain[[i+'_prod' for i in cols]] = train[[i+'_1' for i in cols]].values * train[[i+'_2' for i in cols]].values\ntest[[i+'_prod' for i in cols]] = test[[i+'_1' for i in cols]].values * test[[i+'_2' for i in cols]].values\nfeature_cols += [i+'_prod' for i in cols]\n\nprint('number of features : ',len(feature_cols))\nprint('number of train data : ',len(train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_train = train[feature_cols] \n# y_train = train['contact']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[feature_cols] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nimport optuna\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\n# 데이터 로드\ndata, target = train[feature_cols], train['contact']\ntrain_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n\n# objective function 정의\ndef objective(trial):\n    param = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100)\n    }\n    \n    # LGBM 모델 정의\n    model = lgb.train(param, lgb.Dataset(train_x, label=train_y), 100)\n    y_pred = model.predict(valid_x)\n    \n    # 분류 문제이므로 정확도를 최적화 목표로 설정\n    accuracy = accuracy_score(valid_y, y_pred.round())\n    return accuracy\n\n# 최적화 실행\nstudy = optuna.create_study(direction='maximize')\nwith tqdm(total=100) as pbar:\n    for i in range(100):\n        study.optimize(objective, n_trials=1)\n        pbar.update(1)\n\n# 결과 출력\nprint('Number of finished trials: ', len(study.trials))\nprint('Best trial: ')\ntrial = study.best_trial\nprint('  Value: ', trial.value)\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print('    {}: {}'.format(key, value))","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-02-27 18:26:57,428]\u001b[0m Trial 11 finished with value: 0.9671006418796173 and parameters: {'lambda_l1': 0.014396708938797534, 'lambda_l2': 1.6094054772557866e-08, 'num_leaves': 226, 'feature_fraction': 0.9819309582408979, 'bagging_fraction': 0.6721297899660855, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 11 with value: 0.9671006418796173.\u001b[0m\n 12%|█▏        | 12/100 [12:23<2:03:53, 84.47s/it]","output_type":"stream"}]},{"cell_type":"code","source":"import optuna.visualization as vis\n\n# 각 하이퍼파라미터의 중요도 시각화\nfig = vis.plot_param_importances(study)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nimport optuna\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\n# 데이터 로드\ndata, target = train[feature_cols], train['contact']\ntrain_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n\n# objective function 정의\ndef objective(trial):\n    param = {\n        'objective': 'binary:logistic',\n        'eval_metric': 'logloss',\n        'verbosity': -1,\n        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear']),\n        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n        'max_depth': trial.suggest_int('max_depth', 2, 10),\n        'eta': trial.suggest_float('eta', 1e-8, 1.0, log=True),\n        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n        'min_child_weight': trial.suggest_float('min_child_weight', 1e-8, 10.0, log=True),\n    }\n    \n    # XGBoost 모델 정의\n    dtrain = xgb.DMatrix(train_x, label=train_y)\n    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n    model = xgb.train(param, dtrain, num_boost_round=100)\n    y_pred = model.predict(dvalid)\n    \n    # 분류 문제이므로 정확도를 최적화 목표로 설정\n    accuracy = accuracy_score(valid_y, y_pred.round())\n    return accuracy\n\n# 최적화 실행\nstudy = optuna.create_study(direction='maximize')\nwith tqdm(total=100) as pbar:\n    for i in range(100):\n        study.optimize(objective, n_trials=1)\n        pbar.update(1)\n\n# 결과 출력\nprint('Number of finished trials: ', len(study.trials))\nprint('Best trial: ')\ntrial = study.best_trial\nprint('  Value: ', trial.value)\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print('    {}: {}'.format(key, value)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = vis.plot_param_importances(study)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import catboost as cb\nimport optuna\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\n# 데이터 로드\ndata, target = train[feature_cols], train['contact']\ntrain_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n\n# objective function 정의\ndef objective(trial):\n    param = {\n        'loss_function': 'Logloss',\n        'eval_metric': 'Accuracy',\n        'verbose': False,\n        'iterations': 100,\n        'depth': trial.suggest_int('depth', 4, 10),\n        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 100, log=True),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10),\n        'random_strength': trial.suggest_float('random_strength', 1e-8, 10, log=True),\n        'border_count': trial.suggest_int('border_count', 1, 255),\n        'thread_count': 2\n    }\n    \n    # CatBoost 모델 정의\n    model = cb.CatBoostClassifier(**param)\n    model.fit(train_x, train_y, eval_set=[(valid_x, valid_y)], early_stopping_rounds=20, verbose=False)\n    y_pred = model.predict(valid_x)\n    \n    # 분류 문제이므로 정확도를 최적화 목표로 설정\n    accuracy = accuracy_score(valid_y, y_pred)\n    return accuracy\n\n# 최적화 실행\nstudy = optuna.create_study(direction='maximize')\nwith tqdm(total=100) as pbar:\n    for i in range(100):\n        study.optimize(objective, n_trials=1)\n        pbar.update(1)\n\n# 결과 출력\nprint('Number of finished trials: ', len(study.trials))\nprint('Best trial: ')\ntrial = study.best_trial\nprint('  Value: ', trial.value)\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print('    {}: {}'.format(key, value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = vis.plot_param_importances(study)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}